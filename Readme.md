# ğŸŒ Sign Language Recognition System

A *real-time sign language recognition system* that uses *computer vision* and *machine learning* to detect hand signs and translate them into multiple languages.  

Built with *React (frontend), **Flask (backend), and **MediaPipe (hand tracking)*.

---

## ğŸš€ Features

- ğŸ¥ *Real-time Sign Recognition* â€” Detects hand signs using a live webcam feed.  
- ğŸŒ *Multi-language Translation* â€” Translates recognized signs into multiple languages.  
- ğŸ”Š *Text-to-Speech* â€” Speaks both the original and translated text aloud.  

---

## ğŸ›  Tech Stack

*Frontend*
- âš› React â€” Modern UI framework  
- ğŸ”Œ Socket.IO Client â€” Real-time communication  
- ğŸ¨ CSS3 â€” Responsive styling & animations  

*Backend*
- ğŸ Flask â€” Python web framework  
- ğŸ”„ Socket.IO â€” WebSocket communication  
- âœ‹ MediaPipe â€” Hand landmark detection  
- ğŸ“· OpenCV â€” Computer vision processing  
- ğŸ”¥ PyTorch â€” Deep learning model  
- ğŸŒ Google Translate API â€” Translation service  

*Machine Learning*
- ğŸ§  CNN Model â€” Custom neural network for sign classification  
- âœ‹ MediaPipe Hands â€” Real-time hand tracking  
- ğŸ“Š Scikit-learn â€” Data preprocessing & evaluation  

---

## ğŸ“‹ Prerequisites

Ensure you have the following installed:
- [Python 3.8+](https://www.python.org/downloads/)
- [Node.js 14+](https://nodejs.org/)
- [Git](https://git-scm.com/)
- A *webcam*

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/sign-language-recognition.git
cd sign-language-recognition

```

---


### 2ï¸âƒ£ Backend Setup

Create Virtual Environment (Recommended)

Windows:
```bash

python -m venv sign_env
sign_env\Scripts\activate
```
macOS/Linux:
```bash
python3 -m venv sign_env
source sign_env/bin/activate
```
Install Python Dependencies
```bash
cd backend
pip install -r requirements.txt
```
Environment Configuration

Create a .env file inside the backend/ directory:

# backend/.env
DEFAULT_LANGUAGE=en
FLASK_ENV=development
SERVER_HOST=0.0.0.0
SERVER_PORT=5000


---

### 3ï¸âƒ£ Frontend Setup
```bash
cd frontend
npm install
```

---

### 4ï¸âƒ£ Run the Application

Start Backend Server:
```bash
cd backend
python app.py
```
Server runs on â†’ http://localhost:5000

Start Frontend Server:
```bash
cd frontend
npm run dev
```
Frontend runs on â†’ http://localhost:3000


---
```bash
ğŸ“ Project Structure

sign-language-recognition/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ .env                     # Environment variables
â”‚   â”œâ”€â”€ app.py                   # Main Flask application
â”‚   â”œâ”€â”€ translation_service.py   # Multi-language translation logic
â”‚   â”œâ”€â”€ train_model.py           # Model training script
â”‚   â”œâ”€â”€ collect_data.py          # Data collection utility
â”‚   â”œâ”€â”€ realtime_recognition.py  # Real-time recognition
â”‚   â”œâ”€â”€ image_preprocessing.py   # Image enhancement
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â””â”€â”€ sign_language_model.pkl  # Trained CNN model
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx              # Main React component
â”‚   â”‚   â””â”€â”€ App.css              # Styling
â”‚   â”œâ”€â”€ package.json             # Node dependencies
â”‚   â””â”€â”€ public/
â”‚
â””â”€â”€ README.md
```

---

ğŸ¯ Usage Guide

â–¶ Starting Recognition

1. Click "Start Recognition" to begin the camera feed.


2. Ensure good lighting and clear hand visibility.


3. Keep your hand inside the camera frame.



ğŸŒ Using Translation

1. Select target language from the dropdown.


2. Show a hand sign to the camera.


3. Click "Translate Current Sign" for instant translation.


4. Use "Speak" buttons for audio output.