ğŸŒ Sign Language Recognition & Translation System
A real-time sign language recognition system that uses computer vision and machine learning to detect hand signs and translate them into multiple languages. Built with React frontend, Flask backend, and MediaPipe for hand tracking.

ğŸš€ Features
Real-time Sign Recognition: Detect hand signs using webcam with live video feed

Multi-language Translation: Translate recognized signs into 15+ languages

Text-to-Speech: Speak both original and translated text


ğŸ›  Tech Stack
Frontend
React - Modern UI framework

Socket.IO Client - Real-time communication

CSS3 - Responsive styling with animations

Backend
Flask - Python web framework

Socket.IO - WebSocket communication

MediaPipe - Hand landmark detection

OpenCV - Computer vision processing

PyTorch - Deep learning model

Google Translate API - Free translation service

Machine Learning
CNN Model - Custom neural network for sign classification

MediaPipe Hands - Real-time hand tracking

Scikit-learn - Data preprocessing and evaluation

ğŸ“‹ Prerequisites
Before you begin, ensure you have the following installed:

Python 3.8+ Download here

Node.js 14+ Download here

Webcam - For real-time sign detection

Git - For version control

ğŸš€ Quick Start
1. Clone the Repository
bash
git clone https://github.com/your-username/sign-language-recognition.git
cd sign-language-recognition
2. Backend Setup
Create Virtual Environment (Recommended)
bash
# Windows
python -m venv sign_env
sign_env\Scripts\activate

# macOS/Linux
python3 -m venv sign_env
source sign_env/bin/activate
Install Python Dependencies
bash
cd backend
pip install -r requirements.txt
Environment Configuration
Create a .env file in the backend directory:

bash
# Backend/.env
DEFAULT_LANGUAGE=en
FLASK_ENV=development
SERVER_HOST=0.0.0.0
SERVER_PORT=5000
3. Frontend Setup
bash
cd frontend
npm install
4. Run the Application
Start Backend Server
bash
cd backend
python app.py
The backend will start on http://localhost:5000

Start Frontend Development Server
bash
cd frontend
npm run dev
The frontend will start on http://localhost:3000

ğŸ“ Project Structure
text
sign-language-recognition/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ .env                          # Environment variables
â”‚   â”œâ”€â”€ app.py                        # Main Flask application
â”‚   â”œâ”€â”€ translation_service.py        # Multi-language translation
â”‚   â”œâ”€â”€ train_model.py               # Model training script
â”‚   â”œâ”€â”€ collect_data.py              # Data collection utility
â”‚   â”œâ”€â”€ realtime_recognition.py      # Real-time recognition
â”‚   â”œâ”€â”€ image_preprocessing.py       # Image enhancement
â”‚   â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚   â””â”€â”€ sign_language_model.pkl      # Trained model
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx                  # Main React component
â”‚   â”‚   â””â”€â”€ App.css                  # Styling
â”‚   â”œâ”€â”€ package.json                 # Node dependencies
â”‚   â””â”€â”€ public/
â””â”€â”€ README.md
ğŸ¯ Usage Guide
1. Starting Recognition
Click "Start Recognition" to begin camera feed

Ensure proper lighting and clear hand visibility

Position hand within camera frame

2. Using Translation
Select target language from dropdown

Show hand sign to camera

Click "Translate Current Sign" for instant translation

Use "Speak" buttons for audio output

3. Adding New Signs
Method 1: Using Data Collection Tool
bash
cd backend
python collect_data.py
Follow on-screen instructions to capture new sign images.

Method 2: Manual Dataset Creation
Create folder in sign_data/your_sign_name/

Add training images (JPG/PNG)

Retrain model: python train_model.py

4. Supported Languages
ğŸ‡ºğŸ‡¸ English | ğŸ‡ªğŸ‡¸ Spanish | ğŸ‡«ğŸ‡· French | ğŸ‡©ğŸ‡ª German

ğŸ‡®ğŸ‡¹ Italian | ğŸ‡µğŸ‡¹ Portuguese | ğŸ‡·ğŸ‡º Russian | ğŸ‡¨ğŸ‡³ Chinese

ğŸ‡¯ğŸ‡µ Japanese | ğŸ‡°ğŸ‡· Korean | ğŸ‡¦ğŸ‡ª Arabic | ğŸ‡®ğŸ‡³ Hindi

ğŸ‡§ğŸ‡© Bengali | ğŸ‡®ğŸ‡³ Tamil | ğŸ‡®ğŸ‡³ Telugu | ğŸ‡®ğŸ‡³ Malayalam

ğŸ”§ Advanced Configuration
Model Training
To retrain the model with new data:

bash
cd backend
python train_model.py
The system will:

Scan sign_data/ directory for training data

Extract hand landmarks using MediaPipe

Train CNN model with new classes

Save updated model automatically